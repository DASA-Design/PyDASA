{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ce6a89",
   "metadata": {},
   "source": [
    "# Queue Model (M/M/c/K) Analysis with PyDASA\n",
    "\n",
    "This notebook demonstrates **dimensional analysis** of queueing systems using PyDASA's workflows with a custom dimensional framework. We'll explore how to:\n",
    "\n",
    "1. Define a custom dimensional framework (Time, Structure, Data)\n",
    "2. Model software service variables with custom dimensions\n",
    "3. Use PyDASA's `AnalysisEngine` to derive dimensionless groups\n",
    "4. Understand the M/M/c/K queue model and operational metrics\n",
    "5. Perform sensitivity analysis and Monte Carlo simulation\n",
    "6. Visualize the \"Yoly\" trade-off chart for system design\n",
    "\n",
    "## What is the M/M/c/K Queue Model?\n",
    "\n",
    "The **M/M/c/K** queue model is a fundamental queueing system in performance analysis:\n",
    "\n",
    "- **M** (Markovian arrivals): Request arrivals follow a Poisson process with rate $\\lambda$\n",
    "- **M** (Markovian service): Service times follow exponential distribution with rate $\\mu$\n",
    "- **c**: Number of parallel servers (resources) available\n",
    "- **K**: Maximum system capacity (queue + servers)\n",
    "\n",
    "### Key Performance Metrics:\n",
    "\n",
    "**Average Waiting Time** ($W$):\n",
    "$$\n",
    "W = f(\\lambda, \\mu, c, K, L, ...)\n",
    "$$\n",
    "\n",
    "**Traffic Intensity** ($\\tau$):\n",
    "$$\n",
    "\\tau = \\frac{\\lambda}{\\mu}\n",
    "$$\n",
    "\n",
    "**System Utilization** ($\\rho$):\n",
    "$$\n",
    "\\rho = \\frac{\\lambda}{c \\cdot \\mu}\n",
    "$$\n",
    "\n",
    "### Error Rate and Effective Response\n",
    "\n",
    "The system has an error rate ($err$) that affects the effective response rate:\n",
    "$$\n",
    "\\chi = (1 - err) \\cdot \\lambda\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\chi$ (chi): Effective response rate accounting for errors [S/T]\n",
    "- $err$: Error/failure rate [dimensionless, 0 to 1]\n",
    "- $\\lambda$: Arrival rate [S/T]\n",
    "\n",
    "**Example**: If $\\lambda = 100$ req/s and $err = 0.02$ (2% error rate), then $\\chi = 0.98 \\times 100 = 98$ req/s successfully served.\n",
    "\n",
    "### Custom Dimensional Framework (T, S, D)\n",
    "\n",
    "For software service analysis, we introduce three fundamental dimensions:\n",
    "- **T** (Time): Temporal measurements [seconds]\n",
    "- **S** (Structure): Capacity, servers, queue slots [units]\n",
    "- **D** (Data): Information content, memory [bytes]\n",
    "\n",
    "### The \"Yoly\" Concept\n",
    "\n",
    "**Yoly** is a composite happiness metric that captures the trade-off between:\n",
    "- **Performance**: Fast response times (low $W$)\n",
    "- **Availability**: Low utilization (prevents saturation)\n",
    "- **Memory Efficiency**: Optimal buffer allocation\n",
    "- **Reliability**: Low error rates (high $\\chi/\\lambda$ ratio)\n",
    "\n",
    "A high Yoly score indicates a well-balanced system configuration that keeps users happy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968af6a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "First, let's import PyDASA's core modules for dimensional analysis with custom frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b4df49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERSION: 0.6.8\n",
      "\tPyDASA imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# PyDASA imports\n",
    "import pydasa\n",
    "from pydasa.workflows.phenomena import AnalysisEngine\n",
    "from pydasa.elements.parameter import Variable\n",
    "from pydasa.dimensional.vaschy import Schema\n",
    "\n",
    "# For visualization and analysis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import LogLocator, LogFormatterSciNotation\n",
    "import random\n",
    "\n",
    "\n",
    "print(f\"VERSION: {pydasa.__version__}\")\n",
    "print(\"PyDASA imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0564ee1e",
   "metadata": {},
   "source": [
    "## 2. Define Custom Dimensional Framework\n",
    "\n",
    "For software service analysis, we need a custom dimensional framework that captures the unique characteristics of queueing systems. Unlike physical systems (Length, Mass, Time), we define the following fundamental dimensional units:\n",
    "\n",
    "**Custom Framework Definition:**\n",
    "\n",
    "1. **T (Time)**: Temporal measurements\n",
    "   - Unit: seconds [s].\n",
    "   - Examples: waiting time, service time, inter-arrival time.\n",
    "   - Physical analogy: Similar to Time in PHYSICAL framework.\n",
    "\n",
    "2. **S (Structure)**: System capacity and architectural elements\n",
    "   - Unit: requests [req].\n",
    "   - Examples: number of servers, queue positions, concurrent requests.\n",
    "   - Software-specific: Represents discrete structural resources.\n",
    "\n",
    "3. **D (Data)**: Information content and memory.\n",
    "   - Unit: bit [bit].\n",
    "   - Examples: request payload size, buffer memory, data throughput.\n",
    "   - Software-specific: Quantifies information processing.\n",
    "\n",
    "This framework allows us to perform dimensional analysis on software services, deriving dimensionless numbers that characterize system behavior independent of scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71756108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Custom Framework (T, S, D) Created Successfully! ===\n",
      "\tFramework: CUSTOM\n",
      "\tNumber of FDUs: 3\n",
      "\n",
      "Fundamental Dimensional Units:\n",
      "Symbol     Name            Unit       Description                                            \n",
      "--------------------------------------------------------------------------------\n",
      "T          Time            s          Temporal measurements\n",
      "S          Structure       units      System capacity and structural resources\n",
      "D          Data            bytes      Information content and memory\n"
     ]
    }
   ],
   "source": [
    "# Define custom Fundamental Dimensional Units (FDUs) for software service analysis\n",
    "fdu_list = [\n",
    "    {\n",
    "        \"_idx\": 0,\n",
    "        \"_sym\": \"T\",\n",
    "        \"_fwk\": \"CUSTOM\",\n",
    "        \"description\": \"Temporal measurements\",\n",
    "        \"_unit\": \"s\",\n",
    "        \"_name\": \"Time\"\n",
    "    },\n",
    "    {\n",
    "        \"_idx\": 1,\n",
    "        \"_sym\": \"S\",\n",
    "        \"_fwk\": \"CUSTOM\",\n",
    "        \"description\": \"System capacity and structural resources\",\n",
    "        \"_unit\": \"units\",\n",
    "        \"_name\": \"Structure\"\n",
    "    },\n",
    "    {\n",
    "        \"_idx\": 2,\n",
    "        \"_sym\": \"D\",\n",
    "        \"_fwk\": \"CUSTOM\",\n",
    "        \"description\": \"Information content and memory\",\n",
    "        \"_unit\": \"bytes\",\n",
    "        \"_name\": \"Data\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create custom schema with T, S, D framework\n",
    "schema = Schema(_fwk=\"CUSTOM\",\n",
    "                _fdu_lt=fdu_list, _idx=0)   # type: ignore\n",
    "schema._setup_fdus()\n",
    "\n",
    "print(\"=== Custom Framework Created Successfully! ===\")\n",
    "print(f\"\\tFramework: {schema.fwk}\")\n",
    "print(f\"\\tNumber of FDUs: {len(schema._fdu_lt)}\")\n",
    "print(\"\\nFundamental Dimensional Units:\")\n",
    "print(f\"{'Symbol':<10} {'Name':<15} {'Unit':<10} {'Description':<55}\")\n",
    "print(\"-\" * 80)\n",
    "for fdu in schema._fdu_lt:\n",
    "    print(f\"{fdu._sym:<10} {fdu._name:<15} {fdu._unit:<10} {fdu.description[:60]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6616be",
   "metadata": {},
   "source": [
    "## 3. Define Queue Model Variables\n",
    "\n",
    "We'll define 10 variables for the M/M/c/K queueing system with proper dimensions using the custom T, S, D framework.\n",
    "\n",
    "**Variable Categories:**\n",
    "\n",
    "**INPUT Variables (3)** - Primary system parameters:\n",
    "1. **Î»** (lambda): Arrival rate [S/T]\n",
    "2. **K**: Maximum queue capacity [S]\n",
    "3. **Ï_req**: Data density per request [D/S]\n",
    "\n",
    "**OUTPUT Variable (1)** - Performance metric we want to analyze:\n",
    "1. **W**: Average waiting time [T]\n",
    "\n",
    "**CONTROL Variables (6)** - System configuration and secondary parameters:\n",
    "1. **L**: Average queue length [S]\n",
    "2. **Î¼** (mu): Service rate [S/T]\n",
    "3. **c**: Number of parallel servers [S]\n",
    "4. **B**: Buffer allocated memory [D]\n",
    "5. **err**: Error/failure rate [dimensionless]\n",
    "6. **Ï‡** (chi): Effective response rate [S/T], where Ï‡ = (1 - err) Ã— Î»\n",
    "\n",
    "**Typical Values for a Web Service:**\n",
    "- Arrival rate: 100 req/s\n",
    "- Service rate: 120 req/s (slightly faster than arrivals)\n",
    "- Servers: 4 parallel processors\n",
    "- Queue capacity: 1000 requests\n",
    "- Buffer memory: 1 GB\n",
    "- Data per request: 1 KB\n",
    "- Error rate: 2% (0.02)\n",
    "- Average queue length: 200 requests\n",
    "- Waiting time: 50 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c76e549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Variables defined ===\n",
      "\t- Total: 10\n",
      "\t- Relevant for dimensional analysis: 9\n",
      "\t- Not relevant variables: 1\n",
      "\n",
      "Variable Details:\n",
      "Symbol          Setpoint             Units      Dimensions           Category   Relevant  \n",
      "-----------------------------------------------------------------------------------------------\n",
      "\\lambda_{s}     200.0                req/s      S*T^-1               IN         âœ“         \n",
      "K               10.0                 requests   S                    IN         âœ“         \n",
      "\\rho_{req}      1.0                  MB/req     D*S^-1               IN         âœ“         \n",
      "L               0.9946               requests   S                    OUT        âœ“         \n",
      "W               5.0                  ms         T                    CTRL       âœ“         \n",
      "\\mu_{s}         400.0                req/s      S*T^-1               CTRL       âœ“         \n",
      "\\chi_{s}        97.0                 req/s      S*T^-1               CTRL       âœ“         \n",
      "c               1.0                  req        S                    CTRL       âœ“         \n",
      "B               16                   MB         D                    CTRL       âœ“         \n",
      "err             0.03                 %          n.a.                 CTRL       âœ—         \n"
     ]
    }
   ],
   "source": [
    "# Define the queueing system variables as dictionaries\n",
    "# Each variable is stored with its symbol as the key\n",
    "\n",
    "variables_dict = {\n",
    "    # INPUT VARIABLES (3)\n",
    "    # Arrival rate: Î» [S/T] - requests arriving per unit time\n",
    "    \"\\\\lambda_{s}\": {\n",
    "        \"_idx\": 0,\n",
    "        \"_sym\": \"\\\\lambda_{s}\",\n",
    "        \"_alias\": \"lambda_s\",\n",
    "        \"_fwk\": \"CUSTOM\",\n",
    "        \"_cat\": \"IN\",\n",
    "        \"_name\": \"Arrival Rate\",\n",
    "        \"description\": \"Request arrival rate (Poisson process)\",\n",
    "        \"relevant\": True,\n",
    "        \"_dims\": \"S*T^-1\",\n",
    "        \"_units\": \"req/s\",\n",
    "        \"_setpoint\": 200.0,     # req/s\n",
    "        \"_std_setpoint\": 200.0,\n",
    "        \"_std_mean\": 200.0,\n",
    "        \"_std_min\": 100.0,\n",
    "        \"_std_max\": 500.0,\n",
    "        \"_step\": 10.0,\n",
    "    },\n",
    "\n",
    "    # Queue capacity: K [S] - maximum system capacity\n",
    "    \"K\": {\n",
    "        \"_idx\": 1,\n",
    "        \"_sym\": \"K\",\n",
    "        \"_alias\": \"K\",\n",
    "        \"_fwk\": \"CUSTOM\",\n",
    "        \"_cat\": \"IN\",\n",
    "        \"_name\": \"Queue Capacity\",\n",
    "        \"description\": \"Maximum system capacity (queue + servers)\",\n",
    "        \"relevant\": True,\n",
    "        \"_dims\": \"S\",\n",
    "        \"_units\": \"requests\",\n",
    "        \"_setpoint\": 10.0,      # requests\n",
    "        \"_std_setpoint\": 10.0,\n",
    "        \"_std_mean\": 10.0,\n",
    "        \"_std_min\": 8.0,\n",
    "        \"_std_max\": 12.0,\n",
    "        \"_step\": 1.0,\n",
    "    },\n",
    "    # Data density: Ï_req [D/S] - data per request\n",
    "    \"\\\\rho_{req}\": {\n",
    "        \"_idx\": 2,\n",
    "        \"_sym\": \"\\\\rho_{req}\",\n",
    "        \"_alias\": \"rho_req\",\n",
    "        \"_fwk\": \"CUSTOM\",\n",
    "        \"_cat\": \"IN\",\n",
    "        \"_name\": \"Data Density\",\n",
    "        \"description\": \"Data content per request\",\n",
    "        \"relevant\": True,\n",
    "        \"_dims\": \"D*S^-1\",\n",
    "        \"_units\": \"MB/req\",\n",
    "        \"_setpoint\": 1.0,           # 1 MB per request\n",
    "        \"_min\": 0.001,              # 1 kB per request\n",
    "        \"_max\": 10.0,               # 10 MB per request\n",
    "        \"_std_units\": \"bit/req\",\n",
    "        \"_std_setpoint\": 8000000,\n",
    "        \"_std_mean\": 8000000.0,\n",
    "        \"_std_min\": 8000,\n",
    "        \"_std_max\": 80000000,\n",
    "        \"_step\": 5*8000,           # 5 kbit steps in std units\n",
    "    },\n",
    "\n",
    "    # OUTPUT VARIABLE (1)\n",
    "    # Queue length: L [S] - average number in queue\n",
    "    \"L\": {\n",
    "        \"_idx\": 4,\n",
    "        \"_sym\": \"L\",\n",
    "        \"_alias\": \"L\",\n",
    "        \"_fwk\": \"CUSTOM\",\n",
    "        \"_cat\": \"OUT\",\n",
    "        \"_name\": \"Queue Length\",\n",
    "        \"description\": \"Average queue length\",\n",
    "        \"relevant\": True,\n",
    "        \"_dims\": \"S\",\n",
    "        \"_units\": \"requests\",\n",
    "        \"_setpoint\": 0.9946,        # req, depends on M/M/c/K parameters\n",
    "        \"_std_setpoint\": 0.9946,\n",
    "        \"_std_min\": 0.9946,\n",
    "        \"_std_max\": 4.9750,\n",
    "        \"_std_mean\": 0.9946,\n",
    "    },\n",
    "    \n",
    "    # Waiting time: W [T] - average time in queue\n",
    "    \"W\": {\n",
    "        \"_idx\": 3,\n",
    "        \"_sym\": \"W\",\n",
    "        \"_alias\": \"W\",\n",
    "        \"_fwk\": \"CUSTOM\",\n",
    "        \"_cat\": \"CTRL\",\n",
    "        \"_name\": \"Waiting Time\",\n",
    "        \"description\": \"Average waiting time in queue\",\n",
    "        \"relevant\": True,\n",
    "        \"_dims\": \"T\",\n",
    "        \"_units\": \"ms\",\n",
    "        \"_setpoint\": 5.0,         # waiting time, depends on M/M/c/K parameters\n",
    "        \"_std_min\": 5.0,\n",
    "        \"_std_max\": 13.7,\n",
    "        \"_std_units\": \"s\",\n",
    "        \"_std_setpoint\": 0.0050,\n",
    "        \"_std_mean\": 0.0050,\n",
    "        \"_std_min\": 0.0050,\n",
    "        \"_std_max\": 0.0137,\n",
    "    },\n",
    "\n",
    "    # Service rate: Î¼ [S/T] - requests served per unit time\n",
    "    \"\\\\mu_{s}\": {\n",
    "        \"_idx\": 5,\n",
    "        \"_sym\": \"\\\\mu_{s}\",\n",
    "        \"_alias\": \"mu_comp\",\n",
    "        \"_fwk\": \"CUSTOM\",\n",
    "        \"_cat\": \"CTRL\",\n",
    "        \"_name\": \"Service Rate\",\n",
    "        \"description\": \"Service completion rate per server\",\n",
    "        \"relevant\": True,\n",
    "        \"_dims\": \"S*T^-1\",\n",
    "        \"_units\": \"req/s\",\n",
    "        \"_setpoint\": 400.0,        # req/s, constant\n",
    "        \"_std_units\": \"req/s\",\n",
    "        \"_std_setpoint\": 400.0,\n",
    "        \"_std_mean\": 400.0,\n",
    "        \"_std_min\": 400.0,\n",
    "        \"_std_max\": 500.0,\n",
    "    },\n",
    "\n",
    "    # Response rate: Ï‡ [S/T] - effective throughput\n",
    "    \"\\\\chi_{s}\": {\n",
    "        \"_idx\": 9,\n",
    "        \"_sym\": \"\\\\chi_{s}\",\n",
    "        \"_alias\": \"chi_comp\",\n",
    "        \"_fwk\": \"CUSTOM\",\n",
    "        \"_cat\": \"CTRL\",\n",
    "        \"_name\": \"Response Rate\",\n",
    "        \"description\": \"Effective response rate: Ï‡ = (1 - err) Ã— Î»\",\n",
    "        \"relevant\": True,\n",
    "        \"_dims\": \"S*T^-1\",\n",
    "        \"_units\": \"req/s\",\n",
    "        \"_setpoint\": 97.0,         # (1 - 0.03) Ã— 100 = 97 req/s, depends on error rate and arrival rate\n",
    "        \"_std_units\": \"req/s\",\n",
    "        \"_std_setpoint\": 97.0,\n",
    "        \"_std_min\": 97.0,          # min: (1 - 0.03) Ã— 100\n",
    "        \"_std_max\": 485.0,         # max: (1 - 0.03) Ã— 500\n",
    "    },\n",
    "\n",
    "    # Servers: c [S] - number of parallel servers\n",
    "    \"c\": {\n",
    "        \"_idx\": 6,\n",
    "        \"_sym\": \"c\",\n",
    "        \"_alias\": \"c\",\n",
    "        \"_fwk\": \"CUSTOM\",\n",
    "        \"_cat\": \"CTRL\",\n",
    "        \"_name\": \"Servers\",\n",
    "        \"description\": \"Number of parallel requests handled by servers/processors\",\n",
    "        \"relevant\": True,\n",
    "        \"_dims\": \"S\",\n",
    "        \"_units\": \"req\",\n",
    "        \"_setpoint\": 1.0,           # 1 request (1 server)\n",
    "        \"_std_units\": \"req\",\n",
    "        \"_std_setpoint\": 1.0,\n",
    "        \"_std_min\": 1.0,\n",
    "        \"_std_max\": 4.0,            # up to 8 servers (for scaling analysis)\n",
    "        \"_std_mean\": 2.0,\n",
    "    },\n",
    "\n",
    "    # Buffer memory: B [D] - allocated memory\n",
    "    \"B\": {\n",
    "        \"_idx\": 7,\n",
    "        \"_sym\": \"B\",\n",
    "        \"_alias\": \"B\",\n",
    "        \"_fwk\": \"CUSTOM\",\n",
    "        \"_cat\": \"CTRL\",\n",
    "        \"_name\": \"Buffer Memory\",\n",
    "        \"description\": \"Total allocated buffer memory\",\n",
    "        \"relevant\": True,\n",
    "        \"_dims\": \"D\",\n",
    "        \"_units\": \"MB\",\n",
    "        \"_setpoint\": 16,            # 16 MB\n",
    "        \"_min\": 16,\n",
    "        \"_max\": 32,\n",
    "        \"_std_units\": \"bit\",\n",
    "        \"_std_setpoint\": 1.28e8,    # 128 Mb\n",
    "        \"_std_mean\": 1.28e8,    # 128 Mb\n",
    "        \"_std_min\": 1.28e8,         # 128 Mb\n",
    "        \"_std_max\": 2.56e8,         # 256 Mb, (for scaling analysis)\n",
    "    },\n",
    "\n",
    "    # Error rate: err [dimensionless] - failure probability\n",
    "    # NOT relevant for dimensional analysis (just a coefficient)\n",
    "    \"err\": {\n",
    "        \"_idx\": 8,\n",
    "        \"_sym\": \"err\",\n",
    "        \"_alias\": \"err\",\n",
    "        \"_fwk\": \"CUSTOM\",\n",
    "        \"_cat\": \"CTRL\",\n",
    "        \"_name\": \"Error Rate\",\n",
    "        \"description\": \"Request error/failure rate (0 to 1)\",\n",
    "        \"relevant\": False,         # NOT part of dimensional matrix\n",
    "        \"_dims\": \"n.a.\",               # Dimensionless\n",
    "        \"_units\": \"%\",\n",
    "        \"_setpoint\": 0.03,         # 3% error rate, constant\n",
    "        \"_std_units\": \"\",\n",
    "        \"_std_setpoint\": 0.03,\n",
    "        \"_std_min\": 0.01,\n",
    "        \"_std_max\": 0.04,\n",
    "        \"_std_mean\": 0.03,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Q(M/M/c/K) queueing system variables:\n",
    "# - Î»: Arrival rate (S/T) = 200\n",
    "# - K: Queue capacity (S) = 10\n",
    "# - c: Servers (S) = 1\n",
    "# - Î¼: Service rate (S/T) = 400\n",
    "# - Ï_req: Data density (D/S) = 1 MB/req\n",
    "# - B: Buffer memory (D) = 16 MB\n",
    "# - err: Error rate (dimensionless) = 0.03 (3% failure rate)\n",
    "# - Ï‡: Response rate (S/T) = 97 req/s (calculated as (1 - err) Ã— Î»)\n",
    "# Outputs (calculated from M/M/c/K formulas and error rate):\n",
    "# - W: Waiting time (T) = 0.005 s\n",
    "# - L: Queue length (S) = 0.9946 req\n",
    "# - Wq: Waiting time in queue (T) = 0.0025 s\n",
    "# - Lq: Queue length in queue (S) = 0.4949 req\n",
    "\n",
    "# Convert dictionaries to Variable instances\n",
    "variables = {\n",
    "    sym: Variable(**params) for sym, params in variables_dict.items()\n",
    "}\n",
    "\n",
    "print(\"=== Variables defined ===\")\n",
    "print(f\"\\t- Total: {len(variables)}\")\n",
    "print(f\"\\t- Relevant for dimensional analysis: {sum(1 for v in variables.values() if v.relevant)}\")\n",
    "print(f\"\\t- Not relevant variables: {sum(1 for v in variables.values() if not v.relevant)}\")\n",
    "\n",
    "print(\"\\nVariable Details:\")\n",
    "print(f\"{'Symbol':<15} {'Setpoint':<20} {'Units':<10} {'Dimensions':<20} {'Category':<10} {'Relevant':<10}\")\n",
    "print(\"-\" * 95)\n",
    "for sym, var in variables.items():\n",
    "    dims_str = var.dims if var.dims else \"(N.A.)\"\n",
    "    relevant_str = \"âœ“\" if var.relevant else \"âœ—\"\n",
    "    print(f\"{sym:<15} {var.setpoint:<20} {var.units:<10} {dims_str:<20} {var.cat:<10} {relevant_str:<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92da593d",
   "metadata": {},
   "source": [
    "## 3. Create Dimensional Analysis Engine\n",
    "\n",
    "Now we'll use PyDASA's **AnalysisEngine** (main workflow) to automatically derive dimensionless groups using the Buckingham Pi theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253662e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AnalysisEngine Created ===\n",
      "\t- Framework: CUSTOM\n",
      "\t- Variables: 10\n",
      "\n",
      "Variable Categories:\n",
      "--------------------------------------------------\n",
      "\t- Input variables: 3\n",
      "\t- Output variables: 1\n",
      "\t- Control variables: 6\n"
     ]
    }
   ],
   "source": [
    "# Create the dimensional analysis engine\n",
    "engine = AnalysisEngine(\n",
    "    _idx=0,\n",
    "    _fwk=\"CUSTOM\",\n",
    "    _schema=schema,\n",
    "    _name=\"Software Service Analysis\",\n",
    "    description=\"Dimensional analysis for the Yoly Chart and the queue model M/M/c/K.\"\n",
    ")\n",
    "\n",
    "# Add all variables to the engine\n",
    "engine.variables = variables\n",
    "\n",
    "print(\"=== AnalysisEngine Created ===\")\n",
    "print(f\"\\t- Framework: {engine.fwk}\")\n",
    "print(f\"\\t- Variables: {len(variables)}\\n\")\n",
    "\n",
    "print(\"Variable Categories:\")\n",
    "print(\"-\" * 50)\n",
    "n_inputs = sum(1 for v in variables.values() if v.cat == \"IN\")\n",
    "print(f\"\\t- Input variables: {n_inputs}\")\n",
    "n_outputs = sum(1 for v in variables.values() if v.cat == \"OUT\")\n",
    "print(f\"\\t- Output variables: {n_outputs}\")\n",
    "n_controls = sum(1 for v in variables.values() if v.cat == \"CTRL\")\n",
    "print(f\"\\t- Control variables: {n_controls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c0a479",
   "metadata": {},
   "source": [
    "## 4. Run Dimensional Analysis\n",
    "\n",
    "Execute the complete workflow to generate dimensionless coefficients (Pi groups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f97e85bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Analysis complete! ===\n",
      "\tNumber of Dimensionless Groups: 6\n",
      "\tCoefficients generated: ['\\\\Pi_{0}', '\\\\Pi_{1}', '\\\\Pi_{2}', '\\\\Pi_{3}', '\\\\Pi_{4}', '\\\\Pi_{5}']\n",
      "\n",
      "Dimensionless Coefficients Details:\n",
      "====================================================================================================\n",
      "Coefficient     Expression                          Variable Exponents                                          \n",
      "====================================================================================================\n",
      "\\Pi_{0}         \\frac{L}{K}                         K^-1, L                                                     \n",
      "\\Pi_{1}         \\frac{\\lambda_{s}*W}{K}             \\lambda_{s}, K^-1, W                                        \n",
      "\\Pi_{2}         \\frac{\\mu_{s}}{\\lambda_{s}}         \\lambda_{s}^-1, \\mu_{s}                                     \n",
      "\\Pi_{3}         \\frac{\\chi_{s}}{\\lambda_{s}}        \\lambda_{s}^-1, \\chi_{s}                                    \n",
      "\\Pi_{4}         \\frac{c}{K}                         K^-1, c                                                     \n",
      "\\Pi_{5}         \\frac{B}{K*\\rho_{req}}              K^-1, \\rho_{req}^-1, B                                      \n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run the complete dimensional analysis workflow\n",
    "results = engine.run_analysis()\n",
    "\n",
    "print(f\"=== Analysis complete! ===\")\n",
    "print(f\"\\tNumber of Dimensionless Groups: {len(engine.coefficients)}\")\n",
    "print(f\"\\tCoefficients generated: {list(engine.coefficients.keys())}\\n\")\n",
    "\n",
    "# Display coefficients in a formatted table\n",
    "print(\"Dimensionless Coefficients Details:\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'Coefficient':<15} {'Expression':<35} {'Variable Exponents':<60}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for name, coeff in engine.coefficients.items():\n",
    "    # Extract the coefficient expression\n",
    "    expression = str(coeff.pi_expr) if len(str(coeff.pi_expr)) < 35 else str(coeff.pi_expr)[:32] + \"...\"\n",
    "    \n",
    "    # Format variable exponents as a compact string\n",
    "    exponents_str = \", \".join([f\"{var}^{exp}\" if exp != 1 else var\n",
    "                               for var, exp in coeff.var_dims.items()])\n",
    "    if len(exponents_str) > 58:\n",
    "        exponents_str = exponents_str[:55] + \"...\"\n",
    "    \n",
    "    print(f\"{name:<15} {expression:<35} {exponents_str:<60}\")\n",
    "\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c7a86",
   "metadata": {},
   "source": [
    "## 5. Derive Key Dimensionless Coefficients\n",
    "\n",
    "Now let's use PyDASA's `derive_coefficient()` method to create operationally meaningful coefficients from the Pi groups. Thus, we expect to see:\n",
    "\n",
    "1. **Occupancy Coefficient (Ïƒ)**: Queue capacity utilization - Ïƒ = Î â‚€ = L/K\n",
    "2. **Stall Coefficient (Î´)**: Service blocking indicator - Î´ = Î â‚ = WÂ·Î»/L\n",
    "3. **Efficiency Coefficient (Î·)**: Resource utilization effectiveness - Î· = Î â‚‚â»Â¹Â·Î â‚ƒÂ·Î â‚„â»Â¹ = Ï‡Â·K/(Î¼Â·c)\n",
    "4. **Payload Coefficient (Ï†)**: Data density metric - Ï† = Î â‚… = B/(Ï_reqÂ·K)\n",
    "\n",
    "These derived coefficients connect directly to the Yoly diagram we'll construct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca32fdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "DERIVED DIMENSIONLESS COEFFICIENTS\n",
      "========================================================================================================================\n",
      "Coefficient               Expression                                    Value           Description                        \n",
      "========================================================================================================================\n",
      "Occupancy (Ïƒ)             \\frac{L}{K}                                   0.0995          Queue capacity utilization         \n",
      "Stall (Î´)                 \\frac{\\lambda_{s}*W}{K}                       0.1000          Service blocking indicator         \n",
      "Efficiency (Î·)            \\frac{K*\\chi_{s}}{\\mu_{s}*c}                  2.4250          Resource utilization               \n",
      "Payload (Ï†)               \\frac{B}{K*\\rho_{req}}                        1.6000          Data density metric                \n",
      "========================================================================================================================\n",
      "\n",
      "TRADITIONAL QUEUE OPERATIONAL ASSESSMENT\n",
      "========================================================================================================================\n",
      "Traffic Intensity (Î¸ = Î»/Î¼) = 0.50\n",
      "Utilization (Ï = Î»/(cÂ·Î¼)) = 0.50\n",
      "Occupancy (L/K) = 0.0995\n"
     ]
    }
   ],
   "source": [
    "# Get the original Pi coefficients\n",
    "pi_keys = list(engine.coefficients.keys())\n",
    "\n",
    "# Derive Occupancy Coefficient: Ïƒ = Î â‚€ = L/K\n",
    "sigma_coeff = engine.derive_coefficient(\n",
    "    expr=f\"{pi_keys[0]}\",\n",
    "    symbol=\"\\\\sigma\",\n",
    "    name=\"Occupancy Coefficient\",\n",
    "    description=\"Ïƒ = L/K - Queue occupancy ratio (0 = empty, 1 = full)\",\n",
    "    idx=-1\n",
    ")\n",
    "\n",
    "# Derive Stall Coefficient: Î´ = Î â‚ = WÂ·Î»/L\n",
    "delta_coeff = engine.derive_coefficient(\n",
    "    expr=f\"{pi_keys[1]}\",\n",
    "    symbol=\"\\\\delta\",\n",
    "    name=\"Stall Coefficient\",\n",
    "    description=\"Î´ = WÂ·Î»/L - Service stall/blocking indicator\",\n",
    "    idx=-1\n",
    ")\n",
    "\n",
    "# Derive Efficiency Coefficient: Î· = Î â‚‚â»Â¹Â·Î â‚ƒÂ·Î â‚„â»Â¹ = Ï‡Â·K/(Î¼Â·c)\n",
    "eta_coeff = engine.derive_coefficient(\n",
    "    expr=f\"{pi_keys[2]}**(-1) * {pi_keys[3]} * {pi_keys[4]}**(-1)\",\n",
    "    symbol=\"\\\\eta\",\n",
    "    name=\"Efficiency Coefficient\",\n",
    "    description=\"Î· = Ï‡Â·K/(Î¼Â·c) - Resource utilization effectiveness\",\n",
    "    idx=-1\n",
    ")\n",
    "\n",
    "# Derive Payload Coefficient: Ï† = Î â‚… = B/(Ï_reqÂ·K)\n",
    "phi_coeff = engine.derive_coefficient(\n",
    "    expr=f\"{pi_keys[5]}\",\n",
    "    symbol=\"\\\\phi\",\n",
    "    name=\"Payload Coefficient\",\n",
    "    description=\"Ï† = B/(Ï_reqÂ·K) - Data density metric\",\n",
    "    idx=-1\n",
    ")\n",
    "\n",
    "# Calculate numerical values using stored setpoints\n",
    "sigma_val = sigma_coeff.calculate_setpoint()\n",
    "delta_val = delta_coeff.calculate_setpoint()\n",
    "eta_val = eta_coeff.calculate_setpoint()\n",
    "phi_val = phi_coeff.calculate_setpoint()\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 120)\n",
    "print(\"DERIVED DIMENSIONLESS COEFFICIENTS\")\n",
    "print(\"=\" * 120)\n",
    "print(f\"{'Coefficient':<25} {'Expression':<45} {'Value':<15} {'Description':<35}\")\n",
    "print(\"=\" * 120)\n",
    "print(f\"{'Occupancy (Ïƒ)':<25} {str(sigma_coeff.pi_expr):<45} {sigma_val:<15.4f} {'Queue capacity utilization':<35}\")\n",
    "print(f\"{'Stall (Î´)':<25} {str(delta_coeff.pi_expr)[:45]:<45} {delta_val:<15.4f} {'Service blocking indicator':<35}\")\n",
    "print(f\"{'Efficiency (Î·)':<25} {str(eta_coeff.pi_expr)[:45]:<45} {eta_val:<15.4f} {'Resource utilization':<35}\")\n",
    "print(f\"{'Payload (Ï†)':<25} {str(phi_coeff.pi_expr):<45} {phi_val:<15.4f} {'Data density metric':<35}\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "# Interpret values for operational insights\n",
    "print(\"\\nTRADITIONAL QUEUE OPERATIONAL ASSESSMENT\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "# traffic intensity: t = Î»/Î¼\n",
    "lambda_s = variables[\"\\\\lambda_{s}\"].setpoint\n",
    "mu_s = variables[\"\\\\mu_{s}\"].setpoint\n",
    "theta = lambda_s / mu_s    # type: ignore\n",
    "print(f\"Traffic Intensity (Î¸ = Î»/Î¼) = {theta:.2f}\")\n",
    "\n",
    "# utilization: Ï = Î»/(cÂ·Î¼)\n",
    "c = variables[\"c\"].setpoint\n",
    "rho = lambda_s / (c* mu_s)    # type: ignore\n",
    "print(f\"Utilization (Ï = Î»/(cÂ·Î¼)) = {rho:.2f}\")\n",
    "\n",
    "# Occupancy L/K\n",
    "L = variables[\"L\"].setpoint\n",
    "K = variables[\"K\"].setpoint\n",
    "occupancy = L / K    # type: ignore\n",
    "print(f\"Occupancy (L/K) = {occupancy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38eb51",
   "metadata": {},
   "source": [
    "## 7. Sensitivity Analysis\n",
    "\n",
    "Let's use PyDASA's **SensitivityAnalysis** workflow to understand which variables have the most influence on our dimensionless coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "353a4f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SensitivityAnalysis workflow created ===\n",
      "\tFramework: CUSTOM\n",
      "\tAnalysis type: SYM (Symbolic)\n",
      "\tVariables: 10\n",
      "\tCoefficients to analyze: 10\n",
      "\n",
      "--- Running Symbolic Sensitivity Analysis ---\n",
      "=== Symbolic sensitivity analysis complete! ===\n",
      "\tAnalyzed 10 coefficients\n",
      "\tResults available for: ['SEN_{\\\\Pi_{0}}', 'SEN_{\\\\Pi_{1}}', 'SEN_{\\\\Pi_{2}}', 'SEN_{\\\\Pi_{3}}', 'SEN_{\\\\Pi_{4}}', 'SEN_{\\\\Pi_{5}}', 'SEN_{\\\\sigma}', 'SEN_{\\\\delta}', 'SEN_{\\\\eta}', 'SEN_{\\\\phi}']\n"
     ]
    }
   ],
   "source": [
    "from pydasa.workflows.influence import SensitivityAnalysis\n",
    "\n",
    "# Create sensitivity analysis handler\n",
    "sensitivity = SensitivityAnalysis(\n",
    "    _idx=0,\n",
    "    _fwk=\"CUSTOM\",\n",
    "    _schema=schema,\n",
    "    _name=\"Queue Model Sensitivity Analysis\",\n",
    "    _cat=\"SYM\"  # Symbolic sensitivity analysis\n",
    ")\n",
    "\n",
    "# Configure with variables and coefficients from the engine\n",
    "sensitivity.variables = engine.variables\n",
    "sensitivity.coefficients = engine.coefficients\n",
    "\n",
    "print(\"=== SensitivityAnalysis workflow created ===\")\n",
    "print(f\"\\tFramework: {sensitivity.fwk}\")\n",
    "print(f\"\\tAnalysis type: {sensitivity.cat} (Symbolic)\")\n",
    "print(f\"\\tVariables: {len(sensitivity.variables)}\")\n",
    "print(f\"\\tCoefficients to analyze: {len(sensitivity.coefficients)}\")\n",
    "\n",
    "# Run symbolic sensitivity analysis at mean values\n",
    "print(\"\\n--- Running Symbolic Sensitivity Analysis ---\")\n",
    "sensitivity_results = sensitivity.analyze_symbolic(val_type=\"mean\")\n",
    "\n",
    "print(f\"=== Symbolic sensitivity analysis complete! ===\")\n",
    "print(f\"\\tAnalyzed {len(sensitivity_results)} coefficients\")\n",
    "print(f\"\\tResults available for: {list(sensitivity_results.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15e15816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "SENSITIVITY ANALYSIS RESULTS - Symbolic Differentiation at Mean Values\n",
      "========================================================================================================================\n",
      "\n",
      "Coefficient               SEN_{\\sigma}         (SEN_{\\sigma})\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Variable             Sensitivity          Relative Impact (%)       Description                                            \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "L                    +1.0000e-01          90.95                     ðŸ”´ DOMINANT influence                                   \n",
      "K                    -9.9460e-03          9.05                      ðŸŸ¢ MINOR influence                                      \n",
      "\n",
      "Coefficient               SEN_{\\delta}         (SEN_{\\delta})\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Variable             Sensitivity          Relative Impact (%)       Description                                            \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "W                    +2.0000e+01          99.95                     ðŸ”´ DOMINANT influence                                   \n",
      "K                    -1.0000e-02          0.05                      ðŸŸ¢ MINOR influence                                      \n",
      "\\lambda_{s}          +5.0000e-04          0.00                      ðŸŸ¢ MINOR influence                                      \n",
      "\n",
      "Coefficient               SEN_{\\eta}           (SEN_{\\eta})\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Variable             Sensitivity          Relative Impact (%)       Description                                            \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\\chi_{s}             +1.2500e-02          62.40                     ðŸ”´ DOMINANT influence                                   \n",
      "c                    +6.2500e-03          31.20                     ðŸŸ  MAJOR influence                                      \n",
      "K                    -1.2500e-03          6.24                      ðŸŸ¢ MINOR influence                                      \n",
      "\\mu_{s}              +3.1250e-05          0.16                      ðŸŸ¢ MINOR influence                                      \n",
      "\n",
      "Coefficient               SEN_{\\phi}           (SEN_{\\phi})\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Variable             Sensitivity          Relative Impact (%)       Description                                            \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "K                    -1.6000e-01          100.00                    ðŸ”´ DOMINANT influence                                   \n",
      "\\rho_{req}           -2.0000e-07          0.00                      ðŸŸ¢ MINOR influence                                      \n",
      "B                    +1.2500e-08          0.00                      ðŸŸ¢ MINOR influence                                      \n",
      "\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display sensitivity analysis results in formatted tables\n",
    "print(\"=\" * 120)\n",
    "print(\"SENSITIVITY ANALYSIS RESULTS - Symbolic Differentiation at Mean Values\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "# Get the derived coefficients we care about (Ïƒ, Î´, Î·, Ï†)\n",
    "derived_coeff_keys = [\n",
    "    k for k in sensitivity_results.keys() if not k.startswith(\"SEN_{\\\\Pi\")\n",
    "]\n",
    "\n",
    "for coeff_key in derived_coeff_keys:\n",
    "    sens_data = sensitivity_results[coeff_key]\n",
    "    \n",
    "    # Get coefficient name\n",
    "    if coeff_key in engine.coefficients:\n",
    "        coeff_name = engine.coefficients[coeff_key].name\n",
    "    else:\n",
    "        coeff_name = coeff_key\n",
    "    \n",
    "    print(f\"\\n{'Coefficient':<25} {coeff_key:<20} ({coeff_name})\")\n",
    "    print(\"-\" * 120)\n",
    "    print(f\"{'Variable':<20} {'Sensitivity':<20} {'Relative Impact (%)':<25} {'Description':<55}\")\n",
    "    print(\"-\" * 120)\n",
    "    \n",
    "    # Calculate total sensitivity for relative percentages\n",
    "    total_sens = sum(abs(v) for v in sens_data.values() if isinstance(v, (int, float)))\n",
    "    \n",
    "    # Sort by absolute sensitivity (descending)\n",
    "    sorted_vars = sorted(sens_data.items(), key=lambda x: abs(x[1]) if isinstance(x[1], (int, float)) else 0, reverse=True)\n",
    "    \n",
    "    for var_sym, sens_val in sorted_vars:\n",
    "        if isinstance(sens_val, (int, float)):\n",
    "            # Get variable name\n",
    "            if var_sym in engine.variables:\n",
    "                var_name = engine.variables[var_sym].name\n",
    "            else:\n",
    "                var_name = var_sym\n",
    "            \n",
    "            # Calculate relative impact\n",
    "            rel_impact = (abs(sens_val) / total_sens * 100) if total_sens > 0 else 0\n",
    "            \n",
    "            # Format sensitivity value\n",
    "            sens_str = f\"{sens_val:+.4e}\"\n",
    "            \n",
    "            # Impact description\n",
    "            if rel_impact > 40:\n",
    "                impact_desc = \"ðŸ”´ DOMINANT influence\"\n",
    "            elif rel_impact > 20:\n",
    "                impact_desc = \"ðŸŸ  MAJOR influence\"\n",
    "            elif rel_impact > 10:\n",
    "                impact_desc = \"ðŸŸ¡ MODERATE influence\"\n",
    "            else:\n",
    "                impact_desc = \"ðŸŸ¢ MINOR influence\"\n",
    "            \n",
    "            print(f\"{var_sym:<20} {sens_str:<20} {rel_impact:<25.2f} {impact_desc:<55}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ad5ea",
   "metadata": {},
   "source": [
    "## 7. Grid-Based Monte Carlo Data Generation\n",
    "\n",
    "Instead of random sampling, we'll generate structured data points by systematically varying queue parameters:\n",
    "\n",
    "**Strategy**: Grid search over configurations while varying arrival rate (Î») until near-saturation\n",
    "\n",
    "**Configuration Parameters**:\n",
    "- **err** (Error rate): [0.03, 0.01] â†’ 2 values (3% and 1% failure rates)\n",
    "- **Î¼** (Service rate): [400, 500] req/s â†’ 2 values  \n",
    "- **c** (Servers): [1, 2, 4] â†’ 3 values\n",
    "- **Total configurations**: 2 Ã— 2 Ã— 3 = **12 configurations**\n",
    "\n",
    "**Constants**:\n",
    "- **K** (Capacity) = 10 requests (fixed)\n",
    "- **B** (Buffer) = 16 MB (fixed)\n",
    "- **Ï_req** (Data density) = 1.0 MB/req (fixed)\n",
    "\n",
    "**Lambda Sweep Strategy**:\n",
    "- Start: Î»_min = **200 req/s** (from std_mean)\n",
    "- Stop: When **Ï = Î»/(cÂ·Î¼) â‰¥ 0.95** (near-saturation, avoid instability)\n",
    "- Step: Î”Î» = **10 req/s**\n",
    "\n",
    "**For each configuration**, we'll:\n",
    "1. Vary Î» from 200 to saturation point\n",
    "2. Calculate Ï‡ = (1 - err) Ã— Î»\n",
    "3. Use MMcK queueing model to compute W and L\n",
    "4. Store all variable values for PyDASA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9990cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "STEP A: Generating Configuration Grid\n",
      "==================================================\n",
      "\n",
      "Generated 12 configurations:\n",
      "Config   err      Î¼ (req/s)    c (servers) \n",
      "--------------------------------------------------\n",
      "1        0.01     400.0        1.0         \n",
      "2        0.01     400.0        2.0         \n",
      "3        0.01     400.0        4.0         \n",
      "4        0.01     500.0        1.0         \n",
      "5        0.01     500.0        2.0         \n",
      "6        0.01     500.0        4.0         \n",
      "7        0.04     400.0        1.0         \n",
      "8        0.04     400.0        2.0         \n",
      "9        0.04     400.0        4.0         \n",
      "10       0.04     500.0        1.0         \n",
      "11       0.04     500.0        2.0         \n",
      "12       0.04     500.0        4.0         \n",
      "\n",
      "âœ“ Configuration grid ready: 12 configurations\n",
      "==================================================\n",
      "\n",
      "Constants for Simulation:\n",
      "\t- Queue Capacity (K): 10.0 [req]\n",
      "\t- Buffer Memory (B): 128000000.0 [bit]\n",
      "\t- Data Density (Ï_req): 8000000 [bit/req]\n",
      "\t- Arrival Rate (Î»): 200.0 [req/s]\n",
      "\t- Arrival Rate Step (Î”Î»): 10.0 [req/s]\n",
      "\n",
      "==================================================\n",
      "==================================================\n",
      "STEP B: Creating Queue Model Dataframe\n",
      "==================================================\n",
      "Dataframe created with columns: ['\\\\lambda_{s}', 'K', '\\\\rho_{req}', 'L', 'W', '\\\\mu_{s}', '\\\\chi_{s}', 'c', 'B', 'err']\n",
      "Initial dataframe shape: (0, 10)\n",
      "================================================================================\n",
      "STEP 4: Generating Data with the M/M/c/K Queueing Model\n",
      "================================================================================\n",
      "\t- Config: 1/12: err=0.01, Î¼=400.0, c=1.0\n",
      "\t\tGenerated 19 data points for this configuration.\n",
      "\t- Config: 2/12: err=0.01, Î¼=400.0, c=2.0\n",
      "\t\tGenerated 57 data points for this configuration.\n",
      "\t- Config: 3/12: err=0.01, Î¼=400.0, c=4.0\n",
      "\t\tGenerated 133 data points for this configuration.\n",
      "\t- Config: 4/12: err=0.01, Î¼=500.0, c=1.0\n",
      "\t\tGenerated 29 data points for this configuration.\n",
      "\t- Config: 5/12: err=0.01, Î¼=500.0, c=2.0\n",
      "\t\tGenerated 76 data points for this configuration.\n",
      "\t- Config: 6/12: err=0.01, Î¼=500.0, c=4.0\n",
      "\t\tGenerated 171 data points for this configuration.\n",
      "\t- Config: 7/12: err=0.04, Î¼=400.0, c=1.0\n",
      "\t\tGenerated 19 data points for this configuration.\n",
      "\t- Config: 8/12: err=0.04, Î¼=400.0, c=2.0\n",
      "\t\tGenerated 57 data points for this configuration.\n",
      "\t- Config: 9/12: err=0.04, Î¼=400.0, c=4.0\n",
      "\t\tGenerated 133 data points for this configuration.\n",
      "\t- Config: 10/12: err=0.04, Î¼=500.0, c=1.0\n",
      "\t\tGenerated 29 data points for this configuration.\n",
      "\t- Config: 11/12: err=0.04, Î¼=500.0, c=2.0\n",
      "\t\tGenerated 76 data points for this configuration.\n",
      "\t- Config: 12/12: err=0.04, Î¼=500.0, c=4.0\n",
      "\t\tGenerated 171 data points for this configuration.\n",
      "=== Generated 970 data points!===\n",
      "\n",
      "================================================================================\n",
      "DATA GENERATION SUMMARY\n",
      "================================================================================\n",
      "Total configurations: 12\n",
      "Total data points: 970\n",
      "Average points per config: 80.8\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from src.queueing import Queue\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "# STEP-A: Generate Configuration Grid\n",
    "# ====================================\n",
    "print(\"=\" * 50)\n",
    "print(\"STEP A: Generating Configuration Grid\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define parameter ranges for grid search\n",
    "# Error rates: 1% and 3% for two QoS agrements\n",
    "err_values = [\n",
    "    variables[\"err\"].std_min, \n",
    "    variables[\"err\"].std_max,\n",
    "]\n",
    "\n",
    "# Service rates: 400 and 500 req/s for two different services\n",
    "mu_values = [\n",
    "    variables[\"\\\\mu_{s}\"].std_min,\n",
    "    variables[\"\\\\mu_{s}\"].std_max,\n",
    "]\n",
    "\n",
    "# Server counts: 1, 2, and 4 servers for redundancy/parallelism\n",
    "c_values = [\n",
    "    variables[\"c\"].std_min,\n",
    "    variables[\"c\"].std_mean,\n",
    "    variables[\"c\"].std_max,\n",
    "]          \n",
    "\n",
    "# Generate all combinations (Cartesian product)\n",
    "configs = list(itertools.product(err_values, mu_values, c_values))\n",
    "\n",
    "print(f\"\\nGenerated {len(configs)} configurations:\")\n",
    "print(f\"{'Config':<8} {'err':<8} {'Î¼ (req/s)':<12} {'c (servers)':<12}\")\n",
    "print(\"-\" * 50)\n",
    "for i, (err, mu, c) in enumerate(configs, 1):\n",
    "    print(f\"{i:<8} {err:<8} {mu:<12} {c:<12}\")\n",
    "\n",
    "print(f\"\\nâœ“ Configuration grid ready: {len(configs)} configurations\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# setting constants for te simulation\n",
    "K_cst = variables[\"K\"].std_setpoint          # Queue capacity [req]\n",
    "B_cst = variables[\"B\"].std_setpoint          # Buffer memory [bit]\n",
    "rho_req_cst = variables[\"\\\\rho_{req}\"].std_setpoint  # Data density [bit/req]\n",
    "lambda_zero = variables[\"\\\\lambda_{s}\"].std_setpoint  # Arrival rate [req/s]\n",
    "lambda_step = variables[\"\\\\lambda_{s}\"].step          # Arrival rate [req/s]\n",
    "\n",
    "print(\"\\nConstants for Simulation:\")\n",
    "print(f\"\\t- Queue Capacity (K): {K_cst} [req]\")\n",
    "print(f\"\\t- Buffer Memory (B): {B_cst} [bit]\")\n",
    "print(f\"\\t- Data Density (Ï_req): {rho_req_cst} [bit/req]\")\n",
    "print(f\"\\t- Arrival Rate (Î»): {lambda_zero} [req/s]\")\n",
    "print(f\"\\t- Arrival Rate Step (Î”Î»): {lambda_step} [req/s]\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# STEP B: DEFINE dataframe for data variables\n",
    "print(\"=\" * 50)\n",
    "print(\"STEP B: Creating Queue Model Dataframe\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "q_cols = list(variables.keys())\n",
    "data_df = pd.DataFrame(columns=q_cols)\n",
    "print(f\"Dataframe created with columns: {q_cols}\")\n",
    "print(f\"Initial dataframe shape: {data_df.shape}\")\n",
    "\n",
    "# STEP C: Generate Data Points with MMcK Model\n",
    "# =================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP C: Generating Data with the M/M/c/K Queueing Model\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "rho_threshold = 0.95  # Stop when utilization reaches 95.0 %\n",
    "\n",
    "# Storage for all data points\n",
    "data_points = []\n",
    "\n",
    "# Process each configuration\n",
    "for config_idx, (err, mu, c) in enumerate(configs, 1):\n",
    "    _msg = f\"\\t- Config: {config_idx}/{len(configs)}: \"\n",
    "    _msg += f\"err={err}, Î¼={mu}, c={c}\"\n",
    "    print(_msg)\n",
    "    lambda_t = lambda_zero\n",
    "    config_data = []\n",
    "    rho_t = 0.0\n",
    "    i = 0\n",
    "    while rho_t < rho_threshold:\n",
    "        # Create and evaluate M/M/c/K queue model\n",
    "        q = Queue(\n",
    "            \"M/M/s/K\",\n",
    "            _lambda=lambda_t,   # type: ignore\n",
    "            mu=mu,              # type: ignore\n",
    "            n_servers=c,        # type: ignore\n",
    "            kapacity=K_cst      # type: ignore\n",
    "    )\n",
    "        q.calculate_metrics()\n",
    "        chi_t = lambda_t * (1 - err)    # type: ignore\n",
    "\n",
    "        # new data line\n",
    "        data_t = [\n",
    "            lambda_t,\n",
    "            K_cst,\n",
    "            rho_req_cst,\n",
    "            q.avg_len,\n",
    "            q.avg_wait,\n",
    "            mu,\n",
    "            chi_t,\n",
    "            c,\n",
    "            B_cst,\n",
    "            err,\n",
    "        ]\n",
    "        \n",
    "        data_df.loc[len(data_df)] = data_t\n",
    "\n",
    "        rho_t = q.rho\n",
    "        lambda_t = lambda_t + lambda_step   # type: ignore\n",
    "        i += 1\n",
    "    print(f\"\\t\\tGenerated {i} data points for this configuration.\")\n",
    "        # print(f\"\\t\\tÎ»={q._lambda:.1f} req/s | Ï={q.rho:.4e} | L={q.avg_len:.4e} req | W={q.avg_wait:.4e} s |\")\n",
    "        # config_data.append(q)\n",
    "\n",
    "print(f\"=== Generated {len(data_df)} data points!===\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA GENERATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total configurations: {len(configs)}\")\n",
    "print(f\"Total data points: {len(data_df)}\")\n",
    "print(f\"Average points per config: {len(data_df) / len(configs):.1f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Display sample data and statistics\n",
    "print(\"=\" * 100)\n",
    "print(\"SAMPLE DATA POINTS (First 10 rows)\")\n",
    "print(\"=\" * 100)\n",
    "print(data_df.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"DATA STATISTICS\")\n",
    "print(\"=\" * 100)\n",
    "print(data_df.describe())\n",
    "\n",
    "# STEP 4: adding the data into the PyDASA Varibles\n",
    "\n",
    "data = data_df.to_dict(orient=\"list\")\n",
    "for sym, var in variables.items():\n",
    "    if sym in data:\n",
    "        var.data = data[sym]\n",
    "        msg = f\"- Added data to '{sym}':({var.name}), len={len(var.data)}.\"\n",
    "        print(msg)\n",
    "    else:\n",
    "        msg = f\" - WARN: No data found for '{sym}' ({var.name}), leaving data empty.\"\n",
    "        print(msg)\n",
    "\n",
    "engine.variables = variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e071c0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "STEP 3: Creating Queue Model Dataframe\n",
      "==================================================\n",
      "Dataframe created with columns: ['\\\\lambda_{s}', 'K', '\\\\rho_{req}', 'L', 'W', '\\\\mu_{s}', '\\\\chi_{s}', 'c', 'B', 'err']\n",
      "Initial dataframe shape: (0, 10)\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c264ce41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 3: Generating Data with the M/M/c/K Queueing Model\n",
      "================================================================================\n",
      "\t- Config: 1/12: err=0.01, Î¼=400.0, c=1.0\n",
      "\t\tGenerated 19 data points for this configuration.\n",
      "\t- Config: 2/12: err=0.01, Î¼=400.0, c=2.0\n",
      "\t\tGenerated 57 data points for this configuration.\n",
      "\t- Config: 3/12: err=0.01, Î¼=400.0, c=4.0\n",
      "\t\tGenerated 133 data points for this configuration.\n",
      "\t- Config: 4/12: err=0.01, Î¼=500.0, c=1.0\n",
      "\t\tGenerated 29 data points for this configuration.\n",
      "\t- Config: 5/12: err=0.01, Î¼=500.0, c=2.0\n",
      "\t\tGenerated 76 data points for this configuration.\n",
      "\t- Config: 6/12: err=0.01, Î¼=500.0, c=4.0\n",
      "\t\tGenerated 171 data points for this configuration.\n",
      "\t- Config: 7/12: err=0.04, Î¼=400.0, c=1.0\n",
      "\t\tGenerated 19 data points for this configuration.\n",
      "\t- Config: 8/12: err=0.04, Î¼=400.0, c=2.0\n",
      "\t\tGenerated 57 data points for this configuration.\n",
      "\t- Config: 9/12: err=0.04, Î¼=400.0, c=4.0\n",
      "\t\tGenerated 133 data points for this configuration.\n",
      "\t- Config: 10/12: err=0.04, Î¼=500.0, c=1.0\n",
      "\t\tGenerated 29 data points for this configuration.\n",
      "\t- Config: 11/12: err=0.04, Î¼=500.0, c=2.0\n",
      "\t\tGenerated 76 data points for this configuration.\n",
      "\t- Config: 12/12: err=0.04, Î¼=500.0, c=4.0\n",
      "\t\tGenerated 171 data points for this configuration.\n",
      "\n",
      "âœ“ Generated 970 data points!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DATA GENERATION SUMMARY\n",
      "================================================================================\n",
      "Total configurations: 12\n",
      "Total data points: 970\n",
      "Average points per config: 80.8\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16520a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "SAMPLE DATA POINTS (First 10 rows)\n",
      "====================================================================================================\n",
      " \\lambda_{s}    K  \\rho_{req}        L        W  \\mu_{s}  \\chi_{s}   c           B  err\n",
      "       200.0 10.0   8000000.0 0.994626 0.004976    400.0     198.0 1.0 128000000.0 0.01\n",
      "       210.0 10.0   8000000.0 1.096069 0.005223    400.0     207.9 1.0 128000000.0 0.01\n",
      "       220.0 10.0   8000000.0 1.206876 0.005492    400.0     217.8 1.0 128000000.0 0.01\n",
      "       230.0 10.0   8000000.0 1.327896 0.005783    400.0     227.7 1.0 128000000.0 0.01\n",
      "       240.0 10.0   8000000.0 1.459947 0.006098    400.0     237.6 1.0 128000000.0 0.01\n",
      "       250.0 10.0   8000000.0 1.603781 0.006437    400.0     247.5 1.0 128000000.0 0.01\n",
      "       260.0 10.0   8000000.0 1.760034 0.006802    400.0     257.4 1.0 128000000.0 0.01\n",
      "       270.0 10.0   8000000.0 1.929173 0.007192    400.0     267.3 1.0 128000000.0 0.01\n",
      "       280.0 10.0   8000000.0 2.111440 0.007607    400.0     277.2 1.0 128000000.0 0.01\n",
      "       290.0 10.0   8000000.0 2.306806 0.008046    400.0     287.1 1.0 128000000.0 0.01\n",
      "\n",
      "====================================================================================================\n",
      "DATA STATISTICS\n",
      "====================================================================================================\n",
      "       \\lambda_{s}      K  \\rho_{req}           L           W     \\mu_{s}  \\\n",
      "count   970.000000  970.0       970.0  970.000000  970.000000  970.000000   \n",
      "mean    784.247423   10.0   8000000.0    2.410978    0.003324  456.907216   \n",
      "std     450.982302    0.0         0.0    1.402988    0.001703   49.546151   \n",
      "min     200.000000   10.0   8000000.0    0.400088    0.002000  400.000000   \n",
      "25%     400.000000   10.0   8000000.0    1.189333    0.002332  400.000000   \n",
      "50%     680.000000   10.0   8000000.0    2.137378    0.002747  500.000000   \n",
      "75%    1110.000000   10.0   8000000.0    3.526843    0.003566  500.000000   \n",
      "max    1900.000000   10.0   8000000.0    5.461425    0.012697  500.000000   \n",
      "\n",
      "          \\chi_{s}           c            B         err  \n",
      "count   970.000000  970.000000        970.0  970.000000  \n",
      "mean    764.641237    3.154639  128000000.0    0.025000  \n",
      "std     439.917253    1.128852          0.0    0.015008  \n",
      "min     192.000000    1.000000  128000000.0    0.010000  \n",
      "25%     387.975000    2.000000  128000000.0    0.010000  \n",
      "50%     663.300000    4.000000  128000000.0    0.025000  \n",
      "75%    1079.100000    4.000000  128000000.0    0.040000  \n",
      "max    1881.000000    4.000000  128000000.0    0.040000  \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a95afa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Added data to '\\lambda_{s}':(Arrival Rate), len=970\n",
      "âœ“ Added data to 'K':(Queue Capacity), len=970\n",
      "âœ“ Added data to '\\rho_{req}':(Data Density), len=970\n",
      "âœ“ Added data to 'L':(Queue Length), len=970\n",
      "âœ“ Added data to 'W':(Waiting Time), len=970\n",
      "âœ“ Added data to '\\mu_{s}':(Service Rate), len=970\n",
      "âœ“ Added data to '\\chi_{s}':(Response Rate), len=970\n",
      "âœ“ Added data to 'c':(Servers), len=970\n",
      "âœ“ Added data to 'B':(Buffer Memory), len=970\n",
      "âœ“ Added data to 'err':(Error Rate), len=970\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fe6f3d7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ab559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Creating PyDASA MonteCarloSimulation with Grid Data\n",
      "================================================================================\n",
      "âœ“ MonteCarloSimulation created\n",
      "  - Framework: CUSTOM\n",
      "  - Experiments: 970\n",
      "  - Variables: 10\n",
      "  - Coefficients: 10\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create PyDASA MonteCarloSimulation with grid data\n",
    "from pydasa.workflows.practical import MonteCarloSimulation\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Creating PyDASA MonteCarloSimulation with Grid Data\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create Monte Carlo handler\n",
    "mc_grid = MonteCarloSimulation(\n",
    "    _idx=0,\n",
    "    _fwk=\"CUSTOM\",\n",
    "    _schema=schema,\n",
    "    _name=\"Grid-Based Queue Analysis\",\n",
    "    _cat=\"DATA\",  # Custom category for grid-based sampling\n",
    "    _experiments=len(data_df),\n",
    "    _variables=engine.variables,\n",
    "    _coefficients=engine.coefficients\n",
    ")\n",
    "\n",
    "print(f\"âœ“ MonteCarloSimulation created\")\n",
    "print(f\"\\t- Framework: {mc_grid.fwk}\")\n",
    "print(f\"\\t- Experiments: {mc_grid.experiments}\")\n",
    "print(f\"\\t- Variables: {len(mc_grid._variables)}\")\n",
    "print(f\"\\t- Coefficients: {len(mc_grid._coefficients)}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4af50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a829d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "599135bb",
   "metadata": {},
   "source": [
    "### M/M/c/K System Diagram\n",
    "\n",
    "```\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚  M/M/c/K System (Capacity = K)                      â”‚\n",
    "                    â”‚                                                     â”‚\n",
    "  Arrivals (Î»)      â”‚     Queue          Servers (Î¼)      Response (Ï‡)   â”‚\n",
    "  [S/T]             â”‚   â”Œâ”€â”¬â”€â”¬â”€â”                                          â”‚\n",
    "                    â”‚   â”‚ â”‚ â”‚ â”‚                                          â”‚\n",
    "    â— â— â—  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â†’â”‚ â”‚ â”‚ â”‚â”€â”€â”€â”€â”€â†’  Server 1 (Î¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â—  Served\n",
    "    â— â— â—           â”‚   â””â”€â”´â”€â”´â”€â”˜    â•±                                    â”‚  Requests\n",
    "    â— â— â—           â”‚    (K-c)     â•±                                     â”‚  Ï‡ = (1-err)Â·Î»\n",
    "  (Poisson)         â”‚   slots    â—â”€â”€â”€â”€â”€â†’  Server 2 (Î¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â— â”‚  [S/T]\n",
    "                    â”‚           â•²                                        â”‚\n",
    "  When FULL:        â”‚            â•²                                       â”‚\n",
    "    â— â— â—  â”€â”€â”€â”€â”€X   â”‚             â”€â”€â”€â”€â†’  Server c (Î¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â—â”‚\n",
    "                    â”‚                                                     â”‚\n",
    "  Blocked/          â”‚  â†‘____________________________________________â†‘    â”‚\n",
    "  Rejected          â”‚         K = Total Capacity (queue + servers)       â”‚\n",
    "                    â”‚                                                     â”‚\n",
    "  Error Rate (err)  â”‚  Note: Ï‡ = (1 - err) Â· Î»                          â”‚\n",
    "  Affects Response  â”‚  Some requests fail â†’ reduces effective throughput â”‚\n",
    "  [dimensionless]   â”‚                                                     â”‚\n",
    "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                    \n",
    "  Legend:\n",
    "  - Î» (lambda): Arrival rate [S/T]\n",
    "  - Î¼ (mu): Service rate per server [S/T]\n",
    "  - c: Number of parallel servers [S]\n",
    "  - K: Total capacity (queue + servers) [S]\n",
    "  - Ï‡ (chi): Effective response rate = (1 - err) Â· Î» [S/T]\n",
    "  - err: Error/failure rate [dimensionless, 0 to 1]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
